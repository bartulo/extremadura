{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'nombre': 'mup',\n",
       "  'geom': <shapely.geometry.multipolygon.MultiPolygon at 0x7f8fdcee81d0>,\n",
       "  'sup': 4417.2867}]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import psycopg2\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "from config import config\n",
    "\n",
    "# CONEXIÓN a la BASE DE DATOS\n",
    "\n",
    "params = config()\n",
    "conn = psycopg2.connect(**params)\n",
    "\n",
    "comarca = 'vera'\n",
    "zona = 'losar'\n",
    "\n",
    "# CONDICIONES SINÓPTICAS\n",
    "\n",
    "sql = '''WITH inc as \n",
    "        (SELECT a.*, b.descripcion_corta as causa\n",
    "        FROM \n",
    "            incendios_proximos_ze a,\n",
    "            causas b\n",
    "        WHERE \n",
    "            a.idcausa = b.id\n",
    "            and b.ididioma = 0\n",
    "        ORDER by tot desc)\n",
    "        SELECT inc.*, c.texto, c.descripcion\n",
    "        FROM \n",
    "            inc,\n",
    "            texto_situacion_sinoptica c\n",
    "        WHERE\n",
    "            c.idpif = inc.idpif\n",
    "        '''\n",
    "\n",
    "incendios_cs = gpd.read_postgis(sql, conn)\n",
    "incendios_cs['epa'] = (pd.DatetimeIndex(incendios_cs.deteccion).month > 5) & (pd.DatetimeIndex(incendios_cs.deteccion).month < 11)\n",
    "ss = incendios_cs[['idpif', 'descripcion']].groupby(['descripcion']).count()\n",
    "ss_epa = incendios_cs[incendios_cs.epa == True][['idpif', 'descripcion']].groupby(['descripcion']).count()\n",
    "ss_epb = incendios_cs[incendios_cs.epa == False][['idpif', 'descripcion']].groupby(['descripcion']).count()\n",
    "ss = ss.merge(right=ss_epa, left_index=True, right_index=True, how='left')\n",
    "ss = ss.merge(right=ss_epb, left_index=True, right_index=True, how='left')\n",
    "ss.columns = ['Total', 'EPA', 'EPB']\n",
    "ss = ss[['EPA', 'EPB', 'Total']]\n",
    "ss = ss.fillna(0)\n",
    "ss = ss.convert_dtypes()\n",
    "ss.index.name = 'Situación sinóptica'\n",
    "\n",
    "# CAUSAS\n",
    "\n",
    "causas = pd.read_sql('''\n",
    "            with c as \n",
    "                (select idcausa / 100 as ppal, count(*) as num, \n",
    "                sum(superficiearboladatotal) as sup_arbolada, \n",
    "                sum(superficinoarboladatotal) as sup_no_arbolada \n",
    "                from incendios_proximos_ze \n",
    "                group by idcausa \n",
    "                order by idcausa) \n",
    "            select \n",
    "                ppal, \n",
    "                sum(num) as num_incendios, \n",
    "                sum(sup_arbolada) as sup_arbolada, \n",
    "                sum(sup_no_arbolada) as sup_no_arbolada,\n",
    "                sum(sup_arbolada) + sum(sup_no_arbolada) as sup_total\n",
    "            from \n",
    "                c\n",
    "            group by ppal \n",
    "            order by ppal\n",
    "            ''', conn)\n",
    "\n",
    "causas_detalle = pd.read_sql('''\n",
    "            with c as \n",
    "                (select idcausa, count(*) as num, \n",
    "                sum(superficiearboladatotal) as sup_arbolada, \n",
    "                sum(superficinoarboladatotal) as sup_no_arbolada \n",
    "                from incendios_proximos_ze \n",
    "                group by idcausa \n",
    "                order by idcausa) \n",
    "            select \n",
    "                idcausa,\n",
    "                descripcion_corta,\n",
    "                sum(num) as num_incendios, \n",
    "                sum(sup_arbolada) as sup_arbolada, \n",
    "                sum(sup_no_arbolada) as sup_no_arbolada,\n",
    "                sum(sup_arbolada) + sum(sup_no_arbolada) as sup_total\n",
    "            from \n",
    "                c,\n",
    "                causas \n",
    "            where \n",
    "                c.idcausa = causas.id\n",
    "                and causas.ididioma = 0\n",
    "            group by \n",
    "                descripcion_corta,\n",
    "                idcausa\n",
    "            order by c.idcausa\n",
    "            ''', conn)\n",
    "    \n",
    "causas.index = ['Rayo', 'Negligencia', 'Accidente', 'Intencionado', 'Desconocida', 'Reproducción']\n",
    "causas = causas[['num_incendios', 'sup_arbolada', 'sup_no_arbolada', 'sup_total']]\n",
    "\n",
    "# SEVERIDAD \n",
    "\n",
    "incendios = [{'zona': 'Jerte-Tornavacas', 'idpif': ['1133522', '1143015', '1143273', '574176', '1164099']}, \n",
    "             {'zona': 'Villanueva-Madrigal', 'idpif': ['1122656', '1132420', '1133464', '1163320', '1163391']}, \n",
    "             {'zona': 'Losar', 'idpif': ['1163407', '569396', '1169767', '574250', '1122672']}]\n",
    "\n",
    "severidad = []\n",
    "\n",
    "zonas_dict = {'jerte': 0, 'tornavacas': 0, 'madrigal': 1, 'losar': 2}\n",
    "\n",
    "severidad = incendios[zonas_dict[zona]]\n",
    "severidad['incendios'] = []\n",
    "\n",
    "for n in severidad['idpif']:\n",
    "    perimetro = gpd.read_postgis(\"select * from perimetros_utm where idpif = {}\".format(n), conn)\n",
    "    severidad['incendios'].append({'fecha': perimetro.iloc[0]['fecha'].strftime('%d/%m/%Y'), 'idpif': n})\n",
    "\n",
    "# CATASTRO \n",
    "\n",
    "if zona == 'madrigal':\n",
    "    sql = '''\n",
    "        SELECT nombre, masa, st_union(geom) as geom, sum (area) / 10000 as sup\n",
    "        FROM catastro_mod_{}\n",
    "        GROUP by nombre, masa\n",
    "        '''.format(zona)\n",
    "    sql += ''' union all\n",
    "            select nombre, masa, st_union(geom) as geom, sum(area) / 10000 as sup\n",
    "            from catastro_mod_villanueva\n",
    "            GROUP by nombre, masa\n",
    "            '''\n",
    "    sql += ''' union all\n",
    "            select nombre, masa, st_union(geom) as geom, sum(area) / 10000 as sup\n",
    "            from catastro_mod_valverde\n",
    "            GROUP by nombre, masa\n",
    "            '''\n",
    "elif zona == 'losar':\n",
    "    sql = 'select nombre, st_union(geom) as geom, sum(area) / 10000 as sup from catastro_mod_{} group by nombre'. format(zona)\n",
    "else:\n",
    "    sql = 'select nombre, masa, st_union(geom) as geom, sum(area) / 10000 as sup from catastro_mod_{} group by nombre, masa'. format(zona)\n",
    "\n",
    "parcelas = gpd.read_postgis(sql, conn)\n",
    "catastro = parcelas.to_dict(orient='records')\n",
    "display(catastro)\n",
    "\n",
    "# FORESTALES\n",
    "    \n",
    "forestales = pd.read_sql(\"select forestal, contacto from forestales where zona = '{}'\".format(zona), conn)\n",
    "\n",
    "# HIDROGRAFÍA\n",
    "\n",
    "rios = gpd.read_postgis('''select \n",
    "                row_number() over (order by a.long_km desc) as id_mapa, a.* \n",
    "                from rios a, zona_estudio_{} b \n",
    "                where st_intersects(a.geom, b.geom)\n",
    "                and a.long_km < 50'''.format(zona), conn)\n",
    "\n",
    "# METEO (TODO crear tabla en base de datos para no tener tanto código aquí)\n",
    "datos_meteo = []\n",
    "if comarca == 'vera':\n",
    "    estaciones = ['madrigal', 'piornal']\n",
    "else:\n",
    "    estaciones = ['tornavacas', 'piornal']\n",
    "\n",
    "for estacion in estaciones:\n",
    "    dias_lluvia = pd.read_sql('''\n",
    "                            select estacion, count(*) as dias_lluvia\n",
    "                            from meteo_{} \n",
    "                            where prectotal > 0 and estacion is not null\n",
    "                            and estacion != 'invierno_2020_2021'\n",
    "                            group by estacion \n",
    "                            order by estacion'''.format(estacion), conn)\n",
    "    dias_sin_lluvia_5 = pd.read_sql('''\n",
    "                            select estacion, count(*) as dsl5\n",
    "                            from meteo_{} \n",
    "                            where dias_sin_lluvia_5 is true and estacion is not null\n",
    "                            group by estacion \n",
    "                            order by estacion'''.format(estacion), conn)\n",
    "    dias_sin_lluvia_8 = pd.read_sql('''\n",
    "                            select estacion, count(*) as dsl8\n",
    "                            from meteo_{} \n",
    "                            where dias_sin_lluvia_8 is true and estacion is not null\n",
    "                            group by estacion \n",
    "                            order by estacion'''.format(estacion), conn)\n",
    "    nieve = pd.read_sql('''\n",
    "                            select estacion, count(*) as nieve\n",
    "                            from meteo_{}\n",
    "                            where prectotal > 0 and tmin < 0 and estacion is not null\n",
    "                            group by estacion \n",
    "                            order by estacion'''.format(estacion), conn)\n",
    "    heladas = pd.read_sql('''\n",
    "                            select estacion, count(*) as heladas\n",
    "                            from meteo_{}\n",
    "                            where tmin < 0 and estacion is not null\n",
    "                            group by estacion \n",
    "                            order by estacion'''.format(estacion), conn)\n",
    "    ventana_solana = pd.read_sql('''\n",
    "                            select estacion, count(*) as vs\n",
    "                            from meteo_{} \n",
    "                            where tmax < 21 and tmin > 6 and dias_sin_lluvia_5 is true and estacion is not null\n",
    "                            group by estacion \n",
    "                            order by estacion'''.format(estacion), conn)\n",
    "    ventana_umbria = pd.read_sql('''\n",
    "                            select estacion, count(*) as vu\n",
    "                            from meteo_{}\n",
    "                            where tmax < 21 and tmin > 6 and dias_sin_lluvia_8 is true and estacion is not null\n",
    "                            group by estacion \n",
    "                            order by estacion'''.format(estacion), conn)\n",
    "\n",
    "    meteo = pd.merge(dias_lluvia, dias_sin_lluvia_5, how='left')\n",
    "    meteo = pd.merge(meteo, dias_sin_lluvia_8, how='left')\n",
    "    meteo = pd.merge(meteo, nieve, how='left')\n",
    "    meteo = pd.merge(meteo, heladas, how='left')\n",
    "    meteo = pd.merge(meteo, ventana_solana, how='left')\n",
    "    meteo = pd.merge(meteo, ventana_umbria, how='left')\n",
    "    meteo = meteo.set_index('estacion')\n",
    "    meteo = meteo.fillna(0)\n",
    "    meteo = meteo.convert_dtypes()\n",
    "    meteo.loc['media'] = meteo.mean(axis=0)\n",
    "    meteo.index.name = 'Periodo'\n",
    "    meteo.columns=['días lluvia', '5 días sin lluvia', '8 días sin lluvia', 'nieve', 'heladas', 'ventana solana', 'ventana umbría']\n",
    "    datos_meteo.append({'estacion': estacion, 'meteo':meteo})\n",
    "\n",
    "# VEGETACIÓN\n",
    "\n",
    "habitats = pd.read_sql('''\n",
    "                        select distinct codue, nom_comun, generico, nom_habita, alianza, spsalianza, prioritari \n",
    "                        from atlashabitats2005_extremadura a,\n",
    "                        zona_estudio_{} b\n",
    "                        where st_intersects(st_transform(a.geom, 25830), b.geom)\n",
    "                        '''.format(zona), conn)\n",
    "habitats_prioritarios = habitats[habitats.prioritari == '*']\n",
    "habitats = habitats[habitats.prioritari == 'Np']\n",
    "habitats_anexo = habitats.to_dict(orient='records')\n",
    "\n",
    "# ÁRBOLES SINGULARES\n",
    "\n",
    "arboles_singulares = gpd.read_postgis('''\n",
    "                    select a.* from arboles_singulares a,\n",
    "                    zona_estudio_{} b\n",
    "                    where st_intersects(st_transform(a.geom, 25830), b.geom)\n",
    "                    '''.format(zona), conn).to_dict(orient='records')\n",
    "    \n",
    "# CERRAR CONEXIÓN BASE DE DATOS\n",
    "\n",
    "conn.close()\n",
    "\n",
    "# EXPORTAR \n",
    "\n",
    "capitulos = ['introduccion', 'objetivos', 'ambito', 'requisitos', 'puestos', 'planificacion', 'elementos', 'juicio']\n",
    "\n",
    "env = Environment(loader=FileSystemLoader('static/templates_vera'))\n",
    "template =env.get_template('base.html')\n",
    "output = template.render(\n",
    "    comarca = comarca,\n",
    "    zona = zona,\n",
    "    severidad = severidad,\n",
    "    condiciones_sinopticas = incendios_cs.to_dict(orient='records'),\n",
    "    ss = ss,\n",
    "    catastro = catastro,\n",
    "    forestales = forestales,\n",
    "    capitulos = capitulos,\n",
    "    rios = rios,\n",
    "    datos_meteo = datos_meteo,\n",
    "    causas = causas,\n",
    "    causas_detalle = causas_detalle,\n",
    "    habitats = habitats,\n",
    "    habitats_prioritarios = habitats_prioritarios,\n",
    "    habitats_anexo = habitats_anexo,\n",
    "    arboles_singulares = arboles_singulares\n",
    ")\n",
    "\n",
    "with open('static/html/final.html', 'w') as f:\n",
    "    f.write(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
